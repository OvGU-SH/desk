#' Generates OLS Data and Confidence/Prediction Intervals for Repeated Samples
#'
#' @description This command simulates repeated samples given fixed data of the exogenous predictors and given (true) regression parameters. For each sample generated the results from an OLS regression with level parameter and confidence intervals (CIs) as well as prediction intervals are calculated.
#'
#' @param x (n x k) vector or matrix of exogenous data, where each column represents the data of one of k exogenous predictors. The number of rows represents the sample size n.
#' @param true.par vector of true parameters in the linear model (level and slope parameters). If \code{true.par} is a vector without named elements then coefficeints are named "alpha", "beta1", "beta2", ..., "betak" by default. Otherwise the names specified are used.
#' @param omit vector of indices identifying the exogenous variables to be omitted in the true model, e.g. \code{omit = 1} corresponds to the first exogenous variable to be omitted. This argument can be used to illustrate omitted variable bias in parameter and standard error estimates. Default value is \code{omit = 0}, i.e. no exogenous variable is omitted
#' @param mean expected value of the normal distribution of the error term.
#' @param sd standard deviation of the normal distribution of the error term. Used only for generating simulated y-values. Interval estimators use the estimated sigma.
#' @param rep repetitions, i.e. number of simulated samples. The samples in each matrix generated have enumerated names "SMPL1", "SMPL2", ..., "SMPLs".
#' @param xnew (t x k) matrix of new exogenous data points at which prediction intervals shoud be calculated. t corresponds to the number of new data points, k to the number of exogenous variables in the model. If not specified regular values \code{x} are used (see first argument).
#' @param sig.level significance level for confidence and prediction intervals.
#' @param seed optionally set random seed to arbitrary number if results should be made replicable.
#'
#' @return A list of named data structures. Let s = number of samples, n = sample size, k = number of coefficients, t = number of new data points in \code{xnew} then:
#' \tabular{ll}{
#' \code{x} \tab (n x k matrix): copy of data of exogenous regressors that was passed to the function.\cr
#' \code{y} \tab (n x s matrix): simulated real y values in each sample.\cr
#' \code{fitted} \tab	(n x s matrix): estimated y values in each sample.\cr
#' \code{coef} \tab (k x s matrix): estimated parameters in each sample.\cr
#' \code{true.par} \tab	(k vector): vector of true parameter values (implemented only for \code{plot.confint()}).\cr
#' \code{u} \tab (n x s matrix): random error term in each sample.\cr
#' \code{residuals} \tab (n x s matrix): residuals of OLS estimations in each sample.\cr
#' \code{sig.squ} \tab (s vector): estimated variance of the error term in each sample.\cr
#' \code{var.u} \tab (s vector): variance of random errors drawn in each sample.\cr
#' \code{se} \tab (k x s matrix): estimated standard deviation of the coefficients in each sample.\cr
#' \code{vcov.coef} \tab (k x k x s array): estimated variance-covariance matrix of the coefficients in each sample.\cr
#' \code{confint} \tab (k x 2 x s array): confidence intervals of the coefficients in each sample. Interval bounds are named "lower" and "upper".\cr
#' \code{outside.ci} \tab (k vector): percentage of confidence intervals not covering the true value for each of the regression parameters.\cr
#' \code{y0} \tab	(t x s matrix): simulated real future y values at \code{xnew} in each sample (real line plus real error).\cr
#' \code{y0.fitted} \tab (t x s matrix): point prediction, i.e. stimated y values at \code{xnew} in each sample (regression line).\cr
#' \code{predint} \tab (t x 2 x s array): prediction intervals of future endogenous realizations at exogenous data points specified by \code{xnew}. Intervals are calculated for each sample, respectively. Interval bounds are named "lower" and "upper".\cr
#' \code{sd.pe} \tab (t x s matrix): estimated standard deviation of prediction errors at all exogenous data points in each sample.\cr
#' \code{outside.pi} \tab	(t vector): percentage of prediction intervals not covering the true value \code{y0} at \code{xnew}.\cr
#' \code{bias.coef} \tab (k vector): true bias in parameter estimators if variables are omitted (argument \code{omit} unequal to zero).\cr
#' }
#'
#' @details Let \code{X} be an object generated by \code{sample.rep()} then \code{plot(X, ...)} accepts the following arguments:
#' \tabular{ll}{
#' \code{plot.what = "confint"} \tab plot stacked confidence intervals for all samples. Additional arguments are \code{center = TRUE} (plot center of intervals?), \code{which.coef = 2} (intervals for which coefficient?), \code{center.size = 1} (size of the center dot), \code{lwd = 1} (line width).\cr
#' \code{plot.what = "reglines"} \tab plot regression lines of all samples.\cr
#' \code{plot.what = "scatter"} \tab plot scatter plots of all samples.\cr
#' }
#'
#' @export
#'
#' @examples
#' ## Generate data of two predictors
#' x1 = c(1,2,3,4,5)
#' x2 = c(2,4,5,5,6)
#' x = cbind(x1,x2)
#'
#' ## Generate list of data structures and name it "out"
#' out = sample.rep(x, true.par = c(2,1,4), rep = 10)
#'
#' ## Extract some data
#' out$coef[2,8] # Extract estimated beta1 (i.e. 2nd coeff) in the 8th sample
#' out$coef["beta1","SMPL8"] # Same as above using internal names
#' out$confint["beta1","upper","SMPL5"] # Extract only upper bound of CI of beta 1 from 5th sample
#' out$confint[,,5] # Extract CIs (upper and lower bound) for all parameters from 5th sample
#' out$confint[,,"SMPL5"] # Same as above using internal names
#' out$confint["beta1",,"SMPL5"] # Extract CI of beta 1 from 5th sample
#' out$u.hat[,"SMPL7"] # Extract residuals from OLS estimation of sample 7
#'
#' ## Generate prediction intervals at three specified points of exogenous data (xnew)
#' out = sample.rep(x, true.par = c(2,1,4), rep = 10, xnew = cbind(x1 = c(1.5,6,7), x2 = c(1,3,5.5)))
#' out$predint[,,6] # Prediction intervals at the three data points of xnew in 6th sample
#' out$sd.pe[,6] # Estimated standard deviations of prediction errors in 6th sample
#' out$outside.pi # Percentage of how many intervals miss true y0 realization
#'
#' ## Illustrate that the relative shares of cases when the interval does not cover the
#' ## true value approaches the significance level
#' out = sample.rep(x, true.par = c(2,1,4), rep = 1000)
#' out$outside.ci
#'
#' ## Illustrate omitted variable bias
#' out.unbiased = sample.rep(x, true.par = c(2,1,4))
#' mean(out.unbiased$coef["beta1",]) # approx. equal to beta1 = 1
#' out.biased = sample.rep(x, true.par = c(2,1,4), omit = 2) # omit x2
#' mean(out.biased$coef["beta1",]) # not approx. equal to beta1 = 1
#' out.biased$bias.coef # show the true bias in coefficients
#'
#' ## Simulate a regression with given correlation structure in exogenous data
#' corr.mat = cbind(c(1, 0.9),c(0.9, 1)) # Generate desired corr. structure (high autocorrelation)
#' X = makedata.corr(n = 10, k = 2, CORR = corr.mat) # Generate 10 obs. of 2 exogenous variables
#' out = sample.rep(X, true.par = c(2,1,4), rep = 1) # Simulate a regression
#' out$vcov.coef
#'
#' ## Illustrate confidence intervals
#' out = sample.rep(c(10, 20, 30,50), true.par = c(0.2,0.13), rep = 10, seed = 12)
#' plot(out, plot.what = "confint")
#'
#' ## Plots confidence intervals of alpha with specified \code{xlim} values.
#' plot(out, plot.what = "confint", which.coef = 1, xlim = c(-15,15))
#'
#' ## Illustrate normalitly of dependent variable
#' out = sample.rep(c(10,30,50), true.par = c(0.2,0.13), rep = 200)
#' plot(out, plot.what = "scatter")
#'
#' ## Illustrate confidence bands in a regression
#' plot(out, plot.what = "reglines")
#'
sample.rep = function(x, true.par, omit = 0, mean = 0, sd = 1, rep = 100,
                       xnew = x, sig.level = 0.05, seed = NULL){

# Function to calculate variances of rows (faster than apply(u,2,var))
col.var = function(x, na.rm = FALSE, unbiased = TRUE) {
  N = colSums(!is.na(x), F, 1)
  c = if (unbiased) N-1 else N
  sweep(x, 2:length(dim(x)), colMeans(x,na.rm,1))
  (colSums(x^2, na.rm, 1) - colSums(x, na.rm, 1)^2/N) / c
  }

##########################
## Pre-calculations     ##
##########################

# Static data
set.seed(seed)
x = as.matrix(x)
X = cbind(1, x) # design matrix regular data
n = nrow(X) # Sample size
k = ncol(X) # Number of parameters
xnew = as.matrix(xnew)
xnew = cbind(1, xnew) # design matrix prediction data

# Calculate t-value
t.val = qt(1-sig.level/2, n-k)

# Create sample names and coefficient names
if (is.null(names(true.par))){
  coef.names = c("alpha", if(k == 2){"beta"} else {paste("beta", 1:(k-1), sep = "")})
  } else {
    coef.names = names(true.par)
  }
if(omit != 0){
  coef.names = coef.names[-(omit+1)]
}
sample.names = paste("SMPL",1:rep, sep = "")

# Random draw of n errors u over repeated samples
u = replicate(rep, rnorm(n, mean, sd))
colnames(u) = sample.names
var.u = col.var(u)

# Generate simulated real y values (with error)
y = matrix(NA, nrow = n, ncol = rep, dimnames = list(NULL, sample.names))
for (i in 1:rep){
  y[,i] = X %*% true.par + u[,i]
}

# Calculate static data conditional on omitted variables
if(omit == 0){
  B = rep(0,k)
  XXi = chol2inv(chol(t(X)%*%X))
  M = diag(n) - X %*% XXi %*% t(X)
  n.omit = 0
} else {
  if (omit < 0 || omit > k-1) stop("Argument omit is misspecified, see help.")
  omit = omit + 1 # first variable is second column
  Xo = X[,omit] # copy ommited variables to Xo
  X = X[,-omit] # delete omitted variables from X
  xnew = xnew[,-omit] # delete omitted variables from xnew
  XXi = chol2inv(chol(t(X)%*%X))
  M = diag(n) - X %*% XXi %*% t(X)
  true.par.o = true.par[omit] #copy ommited parameter to true.par.o
  true.par = true.par[-omit] #delete ommited parameter from true.par
  B = as.vector(XXi %*% t(X) %*% Xo %*% true.par.o) # Bias term of coefs
  n.omit = length(omit)
}

# Name the rows of the bias vector
names(B) = coef.names

##########################
## Init data structures ##
##########################

# Regular x-data:
#################

# Estimated y values (regression line, without error)
y.fit = matrix(NA, nrow = n, ncol = rep, dimnames = list(NULL, sample.names))

# Residuals
resid = matrix(NA, nrow = n, ncol = rep, dimnames = list(NULL, sample.names))

# Estimated parameters
coef = matrix(NA, nrow = k - n.omit, ncol = rep, dimnames = list(coef.names, sample.names))

# Estimated standard deviation of estimated parameters
se.coef = coef

# Estimated standard deviation of error term (sigma hat)
s.hat = rep(NA, rep)

# Estimated variances and covariances of all estimated parameters
cov.coef = array(NA, dim = c(k - n.omit, k - n.omit, rep), dimnames = list(coef.names, coef.names, sample.names))

# Confidence intervals
ci = array(NA, dim = c(k - n.omit, 2, rep), dimnames = list(coef.names, c("lower","upper"), sample.names))

# Is true parameter value outside confidence interval?
is.out.ci = coef

# Prediction data xnew:
#######################

# True future y value (true line plus true error, simulated)
y0 = matrix(NA, nrow = dim(xnew)[1], ncol = rep, dimnames = list(NULL, sample.names))

# Estimated future y value (regression line without error), Point prediction
y0.fit = matrix(NA, nrow = dim(xnew)[1], ncol = rep, dimnames = list(NULL, sample.names)) # Punktprognose

# Estimated standard deviation of prediction error y0 - y0.fit
sd.pe = matrix(NA, nrow = dim(xnew)[1], ncol = rep, dimnames = list(as.character(1:dim(xnew)[1]), sample.names))

# Prediction interval
pi = array(NA, dim = c(dim(xnew)[1], 2, rep), dimnames = list(as.character(1:dim(xnew)[1]), c("lower","upper"), sample.names))

# Is true parameter value outside prediction interval?
is.out.pi = y0

##########################
## Fill data structures ##
##########################

# Regular x-data:
#################

# Loop over all samples drawn (rep)
for (i in 1:rep){

  # Residuals
  resid[,i] = M %*% y[,i] # M in the regular case and M1 if omitted variable

  # Estimated y values (regression line, without error)
  y.fit[,i] = y[,i] - resid[,i]

  # Estimated parameters
  coef[,i] = XXi %*% t(X) %*% y[,i] # X in the regular case and X1 if omitted variable

  # Estimated standard deviation of error term (sigma hat)
  s.hat[i] = as.numeric(t(resid[,i]) %*% resid[,i] / (n-k-n.omit))

  # Estimated variances and covariances of all estimated parameters
  cov.coef[,,i] = s.hat[i] * XXi

  # Estimated standard deviation of estimated parameters
  se.coef[,i] = sqrt(diag(cov.coef[,,i]))

  # Confidence intervals
  c = t.val * se.coef[,i]
  ci[,,i] = cbind(coef[,i] - c, coef[,i] + c)
  is.out.ci[,i] = (true.par < ci[,"lower",i]) | (true.par > ci[,"upper",i])

  # Prediction data xnew:
  #######################
  # True future y value (true line plus true error, simulated)
  y0[,i] = xnew %*% true.par + rnorm(dim(xnew)[1], mean, sd)

  # Point prediction: Estimated future y value (regression line without error)
  y0.fit[,i] = as.vector(xnew %*% coef[,i]) # Vector of fitted y-values

  # Est. standard deviation of prediction error y0 - y0.fit (Vector of quadr. forms)
  sd.pe[,i] = sqrt(diag(xnew %*% cov.coef[,,i] %*% t(xnew)) + s.hat[i])

  # Prediction interval
  c = sd.pe[,i] %o% t.val
  pi[,,i] = cbind(y0.fit[,i] - c, y0.fit[,i] + c)
  is.out.pi[,i] = (y0[,i] < pi[,"lower",i]) | (y0[,i] > pi[,"upper",i])
}

# Calculate percentage of intervals including the true parameter
outside.ci = rowSums(is.out.ci)/rep
outside.pi = rowSums(is.out.pi)/rep

out = list( "x" = x,
            "y" = y,
            "fitted" = y.fit,
            "coef" = coef,
            "true.par" = true.par,
            "u" = u,
            "residuals" = resid,
            "sig.squ" = s.hat,
            "var.u" = var.u,
            "se" = se.coef,
            "vcov.coef" = cov.coef,
            "confint" = ci,
            "outside.ci" = outside.ci,
            "y0" = y0,
            "y0.fitted" = y0.fit,
            "predint" = pi,
            "sd.pe" = sd.pe,
            "outside.pi" = outside.pi,
            "bias.coef" = B
            )

attr(out, "title") = NULL
attr(out, "type") = "repsamp"
attr(out, "details") = F
#attr(out, "c.type") = c.type
class(out) = c("desk")

return(out)
}
